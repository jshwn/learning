#   Transformer
*   참고문헌: attention is all you need.


*   Attention Function: $Attention(Q, K, V) = Attention Value$
    *   주어진 쿼리 $Q$에 대하여
    *   모든 키들의 집합 $K$에 대하여 모든 키 $k$와 쿼리 $Q$의 유사도를 구하고
    *   그 유사도를 키 $k$에 매핑되어 있는 value에 반영해준다.


##  BERT

